{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VinOnyi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\VinOnyi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import wikipedia as wk\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('Corona.txt', 'r',errors='ignore')\n",
    "#data = open('HR.txt', 'r',errors='ignore')\n",
    "raw = data.read()\n",
    "raw = raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(text):\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "    #word tokenization\n",
    "    word_token = nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
    "    \n",
    "    #remove ASCII\n",
    "    new_words = []\n",
    "    for word in word_token:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8','ignore')\n",
    "        new_words.append(new_word)\n",
    "        \n",
    "    #remove tags\n",
    "    rmv = []\n",
    "    for w in new_words:\n",
    "        text = re.sub(\"&lt;/?.*?&gt;\", \"&lt;&gt;\", w)\n",
    "        rmv.append(text)\n",
    "    \n",
    "    #pos tagging and lemmatization\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemma_list=[]\n",
    "    rmv = [i for i in rmv if i]\n",
    "    for token, tag in nltk.pos_tag(rmv):\n",
    "        lemma = lmtzr.lemmatize(token, tag_map[tag[0]])\n",
    "        lemma_list.append(lemma)\n",
    "    return lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcome_input = (\"hello\", \"hi\", \"greetings\", \"hey\", \"whats up\", \"niaje\", \"wachane\")\n",
    "welcome_response = [\"hi\", \"hey\", \"hi there\", \"poa sana\", \"antie\", \"Iam glad you are talking to me\"]\n",
    "def welcome(user_response):\n",
    "    for word in user_response.split():\n",
    "        if word.lower() in welcome_input:\n",
    "            return random.choice(welcome_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateResponse(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=Normalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    #vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    vals = linear_kernel(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0) or \"tell me about\" in user_response:\n",
    "        print(\"Checking Wikipedia\")\n",
    "        if user_response:\n",
    "            robo_response = wikipedia_data(user_response)\n",
    "            return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response\n",
    "    \n",
    "#wikipedia search\n",
    "def wikipedia_data(input):\n",
    "    reg_ex = re.search('tell me about (.*)', input)\n",
    "    try:\n",
    "        if reg_ex:\n",
    "            topic = reg_ex.group(1)\n",
    "            wiki = wk.summary(topic, sentences = 3)\n",
    "            return wiki\n",
    "    except Exception as e:\n",
    "            print(\"No content found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Dominic and I'm here to help you. If you want to exit, type Bye!\n",
      "\n",
      "\n",
      "hey\n",
      "\n",
      "\n",
      "Dominic : Iam glad you are talking to me\n",
      "\n",
      "\n",
      "corona\n",
      "\n",
      "\n",
      "Dominic : Checking Wikipedia\n",
      "None\n",
      "\n",
      "\n",
      "covid-19\n",
      "\n",
      "\n",
      "Dominic : covid-19 courses can be found here.\n",
      "\n",
      "\n",
      "29 february\n",
      "\n",
      "\n",
      "Dominic : see also updated who recommendations on\n",
      "international traffic, published on 29 february 20204\n",
      ".\n",
      "\n",
      "\n",
      "monitors\n",
      "\n",
      "\n",
      "Dominic : who also monitors other sources of information: iata1\n",
      ", sos international2 and countries’ official websites.\n",
      "\n",
      "\n",
      "number of additional health measures\n",
      "\n",
      "\n",
      "Dominic : many states parties are\n",
      "implementing additional health measures against countries other than china.\n",
      "\n",
      "\n",
      "Xizang \n",
      "\n",
      "\n",
      "Dominic : 1 https://www.iatatravelcentre.com/international-travel-document-news/1580226297.htm\n",
      "2 https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening\n",
      "3 https://www.iata.org/en/pressroom/pr/2020-03-02-01/\n",
      "4 https://www.who.int/ith/2019-ncov_advice_for_international_traffic-rev/en/\n",
      "figure 1. number of additional health measures by type\n",
      "figure 2. number and types of public health rationale for implementing additional health measures\n",
      "surveillance\n",
      "table 1. confirmed and suspected cases of covid-19 acute respiratory disease reported by provinces, regions and\n",
      "cities in china, data as of 10 march 2020\n",
      "province/\n",
      "region/\n",
      "city\n",
      "population\n",
      "(10,000s)\n",
      "in last 24 hours cumulative\n",
      "confirmed\n",
      "cases\n",
      "suspected\n",
      "cases\n",
      "deaths confirmed\n",
      "cases\n",
      "deaths\n",
      "hubei 5917 17 13 17 67760 3024\n",
      "guangdong 11346 1 0 0 1353 8\n",
      "henan 9605 0 0 0 1272 22\n",
      "zhejiang 5737 0 0 0 1215 1\n",
      "hunan 6899 0 0 0 1018 4\n",
      "anhui 6324 0 0 0 990 6\n",
      "jiangxi 4648 0 0 0 935 1\n",
      "shandong 10047 0 0 0 758 6\n",
      "jiangsu 8051 0 0 0 631 0\n",
      "chongqing 3102 0 0 0 576 6\n",
      "sichuan 8341 0 0 0 539 3\n",
      "heilongjiang 3773 0 0 0 481 13\n",
      "beijing 2154 1 9 0 429 8\n",
      "shanghai 2424 0 12 0 342 3\n",
      "hebei 7556 0 0 0 318 6\n",
      "fujian 3941 0 0 0 296 1\n",
      "guangxi 4926 0 0 0 252 2\n",
      "shaanxi 3864 0 0 0 245 1\n",
      "yunnan 4830 0 0 0 174 2\n",
      "hainan 934 0 0 0 168 6\n",
      "guizhou 3600 0 1 0 146 2\n",
      "tianjin 1560 0 1 0 136 3\n",
      "shanxi 3718 0 0 0 133 0\n",
      "liaoning 4359 0 0 0 125 1\n",
      "gansu 2637 0 0 0 124 2\n",
      "hong kong sar 745 1 0 0 115 3\n",
      "jilin 2704 0 0 0 93 1\n",
      "xinjiang 2487 0 0 0 76 3\n",
      "ningxia 688 0 0 0 75 0\n",
      "inner mongolia 2534 0 0 0 75 1\n",
      "taipei and environs 2359 0 0 0 45 1\n",
      "qinghai 603 0 0 0 18 0\n",
      "macao sar 66 0 0 0 10 0\n",
      "xizang 344 0 0 0 1 0\n",
      "total 142823 20 36 17 80924 3140\n",
      "table 2. countries, territories or areas outside china with reported laboratory-confirmed covid-19 cases and\n",
      "deaths.\n",
      "\n",
      "\n",
      "STRATEGIC OBJECTIVES\n",
      "\n",
      "\n",
      "Dominic : - interrupted transmission indicates locations where interruption of transmission has been demonstrated (details to be determined)\n",
      "** “territories” include territories, areas, overseas dependencies and other jurisdictions of similar status\n",
      "figure 2. epidemic curve of confirmed covid-19 cases reported outside of china (n=32 778), by date of report and\n",
      "who region through 10 march 2020\n",
      "strategic objectives\n",
      "who’s strategic objectives for this response are to:\n",
      "• interrupt human-to-human transmission including reducing secondary infections among close contacts\n",
      "and health care workers, preventing transmission amplification events, and preventing further\n",
      "international spread*;\n",
      "• identify, isolate and care for patients early, including providing optimized care for infected patients;\n",
      "• identify and reduce transmission from the animal source;\n",
      "• address crucial unknowns regarding clinical severity, extent of transmission and infection, treatment\n",
      "options, and accelerate the development of diagnostics, therapeutics and vaccines;\n",
      "• communicate critical risk and event information to all communities and counter misinformation;\n",
      "• minimize social and economic impact through multisectoral partnerships.\n",
      "\n",
      "\n",
      "achieved\n",
      "\n",
      "\n",
      "Dominic : *this can be achieved through a combination of public health measures, such as rapid identification, diagnosis\n",
      "and management of the cases, identification and follow up of the contacts, infection prevention and control in\n",
      "health care settings, implementation of health measures for travelers, awareness-raising in the population and\n",
      "risk communication.\n",
      "\n",
      "\n",
      "PREPAREDNESS AND RESPONSE of corona\n",
      "\n",
      "\n",
      "Dominic : preparedness and response\n",
      "• to view all technical guidance documents regarding covid-19, please go to this webpage.\n",
      "\n",
      "\n",
      "who\n",
      "\n",
      "\n",
      "Dominic : Checking Wikipedia\n",
      "None\n",
      "\n",
      "\n",
      "who has developed\n",
      "\n",
      "\n",
      "Dominic : if you develop fever, cough and difficulty breathing, seek medical advice promptly as this may be due to a respiratory infection or other serious condition.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"My name is Dominic and I'm here to help you. If you want to exit, type Bye!\")\n",
    "while(flag == True):\n",
    "    print('\\n')\n",
    "    user_response = input()\n",
    "    print('\\n')\n",
    "    user_response = user_response.lower()\n",
    "    if(user_response not in ['bye', 'shutdown', 'exit', 'quit']):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag = False\n",
    "            print('Dominic : Welcome!!!')\n",
    "        else:\n",
    "            if(welcome(user_response) != None):\n",
    "                print(\"Dominic : \" + welcome(user_response))\n",
    "            else:\n",
    "                print(\"Dominic : \", end = \"\")\n",
    "                print(generateResponse(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Dominic : Bye!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
